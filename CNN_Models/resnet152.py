# -*- coding: utf-8 -*-
"""ResNet152

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aAmClB3NeaTIZqWSA-qKoiU1SJ_Qv5Ve
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

import os
from PIL import Image

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, LSTM, GRU, Lambda, Input, MaxPooling2D, Dropout, Activation, BatchNormalization, AveragePooling2D
from tensorflow.keras import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l1_l2
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import load_model
from tensorflow.keras import layers

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow.keras.backend as K
from tensorflow.keras import regularizers
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l2
from tensorflow import keras
from tensorflow.keras import models
from tensorflow.keras.applications import ResNet152

#from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.models import Model
import keras
densenet = ResNet152(include_top=False, weights='imagenet', input_shape=(256,256,3))
output = densenet.layers[-1].output
output = keras.layers.Flatten()(output)
densenet = Model(densenet.input, output)
for layer in densenet.layers:
    layer.trainable = False
densenet.summary()

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers
# # we use SGD with a low learning rate
from tensorflow.keras.optimizers import Nadam
from tensorflow.keras.optimizers import Adam
model = Sequential()
model.add(densenet)
model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_dim=256))
model.add(Dropout(0.4))
model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_dim=128))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer=SGD(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

gens = []
ppl = 26

pathv = '/content/drive/MyDrive/Graph_CNN_Project/VG_Dataset'

for i in range(ppl):
  imgdatagen = ImageDataGenerator(rescale=1./255)
  imgdatagen = imgdatagen.flow_from_directory(
    pathv+'/Person'+str(i+1),
    batch_size=300,
    class_mode='binary'
  )
  gens.append(imgdatagen)


X, y = [], []

for i in range(ppl):
  images, labels = gens[i].next()
  for im in images:
    X.append(im)
  for lbl in labels:
    y.append(lbl)
  print("Person " + str(i+1) + " done!")

X = np.array(X)
y = np.array(y)

X.shape, y.shape

opt = SGD(learning_rate = 0.0001)
model.compile(optimizer = opt , loss = 'binary_crossentropy', metrics = ['accuracy'])

def get_data_for_ith_person(person):
  st, ed = person*300, (person+1)*300
  x_sub, x_rest = X[st:ed], np.concatenate((X[:st], X[ed:]))
  y_sub, y_rest = y[st:ed], np.concatenate((y[:st], y[ed:]))

  return x_sub, y_sub, x_rest, y_rest

histories = []

# keep changing this for every person - DO NOT DO IN LOOPS
person = 25
x_sub, y_sub, x_rest, y_rest = get_data_for_ith_person(person)
hist = model.fit(x_rest, y_rest, batch_size = 15, validation_data=(x_sub, y_sub), shuffle = True, epochs=10)
histories.append(hist)

#pwd

# Garbage Collector - use it like gc.collect()
import gc

# Custom Callback To Include in Callbacks List At Training Time
class GarbageCollectorCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        gc.collect()

gc.collect()

from tensorflow.keras import backend as K
K.clear_session()

#cd /content/drive/MyDrive/Graph_CNN_Custom_Model/Person3

#cd ..

#full_model.save("sscv_rkt_person3.h5")

